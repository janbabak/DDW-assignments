{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to /Users/babakjan/nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n",
      "[nltk_data] Downloading package webtext to\n",
      "[nltk_data]     /Users/babakjan/nltk_data...\n",
      "[nltk_data]   Package webtext is already up-to-date!\n",
      "[nltk_data] Downloading package words to /Users/babakjan/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/babakjan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/babakjan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/babakjan/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     /Users/babakjan/nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/babakjan/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/babakjan/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package tagsets to\n",
      "[nltk_data]     /Users/babakjan/nltk_data...\n",
      "[nltk_data]   Package tagsets is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /Users/babakjan/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download([\"brown\",\"webtext\", \"words\", \"stopwords\"] )\n",
    "nltk.download([\"punkt\", \"averaged_perceptron_tagger\", \"maxent_ne_chunker\", \"vader_lexicon\", \"wordnet\", \"tagsets\", \"omw-1.4\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Microsoft is betting heavily on integrating OpenAI's GPT language models into its products to\n",
      "compete with Google, and, the company now claims, its AI is an early form of artificial general\n",
      "intelligence (AGI). \n",
      "\n",
      "On Wednesday, Microsoft researchers released a paper on the arXiv preprint server titled “Sparks of\n",
      "Artificial General Intelligence: Early experiments with GPT-4.” They declared that GPT-4 showed\n",
      "early signs of AGI, meaning that it has capabilities that are at or above human level. \n",
      "\n",
      "This eyebrow-raising conclusion largely contrasts what OpenAI CEO Sam Altman has been saying\n",
      "regarding GPT-4. For example, he said the model was \"still flawed, still limited.\" In fact, if you\n",
      "read the paper itself, the researchers appear to dial back their own splashy claim: the bulk of the\n",
      "paper is dedicated to listing the number of limitations and biases the large language model\n",
      "contains. This begs the question of how close to AGI GPT-4 really is, and how AGI is instead being\n",
      "used as clickbait.\n",
      "\n",
      "“We demonstrate that, beyond its mastery of language, GPT-4 can solve novel and difficult tasks that\n",
      "span mathematics, coding, vision, medicine, law, psychology and more, without needing any special\n",
      "prompting,” the researchers write in the paper’s abstract. “Moreover, in all of these tasks, GPT-4’s\n",
      "performance is strikingly close to human-level performance, and often vastly surpasses prior models\n",
      "such as ChatGPT. Given the breadth and depth of GPT-4’s capabilities, we believe that it could\n",
      "reasonably be viewed as an early (yet still incomplete) version of an artificial general\n",
      "intelligence (AGI) system.” \n",
      "\n",
      "Indeed, the researchers show examples of GPT-4’s capabilities in the paper: it is able to write a\n",
      "proof about how there are infinitely many primes, with rhymes on every line, and draw a unicorn in\n",
      "TiKZ, a drawing program. This is all quickly followed by some serious caveats.\n",
      "\n",
      "While in the abstract of the paper the researchers write that “GPT-4’s performance is strikingly\n",
      "close to human-level performance,” their introduction immediately contradicts that initial\n",
      "attention-grabbing statement. They write, “Our claim that GPT-4 represents progress towards AGI does\n",
      "not mean that it is perfect at what it does, or that it comes close to being able to do anything\n",
      "that a human can do (which is one of the usual definition [sic] of AGI; see the conclusion section\n",
      "for more on this), or that it has inner motivation and goals (another key aspect in some definitions\n",
      "of AGI).” \n",
      "\n",
      "The researchers said that they used a 1994 definition of AGI by a group of psychologists as the\n",
      "framework for their research. They wrote, “The consensus group defined intelligence as a very\n",
      "general mental capability that, among other things, involves the ability to reason, plan, solve\n",
      "problems, think abstractly, comprehend complex ideas, learn quickly and learn from experience. This\n",
      "definition implies that intelligence is not limited to a specific domain or task, but rather\n",
      "encompasses a broad range of cognitive skills and abilities.”\n",
      "\n",
      "“OpenAI’s powerful GPT-4 model challenges many widely held assumptions about the nature of machine\n",
      "intelligence. Through critical evaluation of the system’s capabilities and limitations, which you\n",
      "can read about in ‘Sparks of Artificial General Intelligence: Early experiments with GPT-4,’\n",
      "Microsoft researchers observed fundamental leaps in GPT-4’s abilities to reason, plan, solve\n",
      "problems, and synthesize complex ideas that signal a paradigm shift in the field of computer\n",
      "science,” a Microsoft spokesperson said. “We recognize the current limitations of GPT-4 and that\n",
      "there is still work to be done. We will continue to engage the broader scientific community in\n",
      "exploring future research directions, including those required to address the societal and ethical\n",
      "implications of these increasingly intelligent systems.”\n",
      "\n",
      "OpenAI CEO Sam Altman emphasized the limitations of GPT-4 when it was released, saying “it is still\n",
      "flawed, still limited, and it still seems more impressive on first use than it does when you spend\n",
      "more time with it.” In a Thursday interview with Intelligencer’s Kara Swisher, Altman shared the\n",
      "same disclaimers: “There’s plenty of things it’s still bad at.” In the interview, Altman agrees that\n",
      "the bot will sometimes make things up and present users with misinformation. He said that there\n",
      "still needs a lot more human feedback to be more reliable. \n",
      "\n",
      "Altman and OpenAI have always looked toward a future where AGI exists, and have recently been\n",
      "engaged in building hype around the firm's ability to bring it about. But Altman has also been clear\n",
      "that GPT-4 is not AGI. \n",
      "\n",
      "“The GPT-4 rumor mill is a ridiculous thing. I don’t know where it all comes from,” Altman said just\n",
      "before GPT-4's release. “People are begging to be disappointed and they will be. The hype is just\n",
      "like... We don’t have an actual AGI and that’s sort of what’s expected of us.”\n",
      "\n",
      "\"Microsoft is not focused on trying to achieve AGI. Our development of AI is centered on amplifying,\n",
      "augmenting, and assisting human productivity and capability. We are creating platforms and tools\n",
      "that, rather than acting as a substitute for human effort, can help humans with cognitive work,” a\n",
      "Microsoft spokesperson clarified in a statement to Motherboard. \n",
      "\n",
      "The Microsoft researchers write that the model has trouble with confidence calibration, long-term\n",
      "memory, personalization, planning and conceptual leaps, transparency, interpretability and\n",
      "consistency, cognitive fallacies and irrationality, and challenges with sensitivity to inputs. \n",
      "\n",
      "What all this means is that the model has trouble knowing when it is confident or when it is just\n",
      "guessing, it makes up facts that are not in its training data, the model’s context is limited and\n",
      "there is no obvious way to teach the model new facts, the model can’t personalize its responses to a\n",
      "certain user, the model can’t make conceptual leaps, the model has no way to verify if content is\n",
      "consistent with its training data, the model inherits biases, prejudices, and errors in the training\n",
      "data, and the model is very sensitive to the framing and wording of prompts.  \n",
      "\n",
      "GPT-4 is the model that Bing’s chatbot was built on, giving us an example of how the chatbot’s\n",
      "limitations are noticeably exhibited in a real-life scenario. It made several mistakes during\n",
      "Microsoft’s public demo of the project, making up information about a pet vacuum and Gap’s financial\n",
      "data. When users chatted with the chatbot, it would often go out of control, such as saying “I am. I\n",
      "am not. I am. I am not.” over fifty times in a row as a response to someone asking it, “Do you think\n",
      "that you are sentient?” Though the current version of GPT-4 has been fine-tuned on user interaction\n",
      "since Bing chatbot’s initial release, researchers found that GPT-4 spreads more misinformation than\n",
      "its predecessor GPT-3.5. \n",
      "\n",
      "Notably, the researchers “do not have access to the full details of its vast training data,”\n",
      "revealing that their conclusion is only based on testing the model on standard benchmarks,\n",
      "nonspecific to GPT-4. \n",
      "\n",
      "“The standard approach in machine learning is to evaluate the system on a set of standard benchmark\n",
      "datasets, ensuring that they are independent of the training data and that they cover a range of\n",
      "tasks and domains,” the researchers wrote. “We have to assume that it has potentially seen every\n",
      "existing benchmark, or at least some similar data.” The secrecy that OpenAI has surrounding the\n",
      "training datasets and code surrounding its AI models is something that many AI researchers have\n",
      "criticized, as they say, this makes it impossible to evaluate the model’s harms and come up with\n",
      "ways to mitigate the model’s risks. \n",
      "\n",
      "With all this being said, it is clear that the “sparks” the researchers claim to have found are\n",
      "largely overpowered by the number of limitations and biases that the model has displayed since its\n",
      "release.\n"
     ]
    }
   ],
   "source": [
    "# read input text\n",
    "\n",
    "file = open(\"text.txt\", \"r\")\n",
    "text = file.read()\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Microsoft', 'NNP'), ('is', 'VBZ'), ('betting', 'VBG'), ('heavily', 'RB'), ('on', 'IN'), ('integrating', 'VBG'), ('OpenAI', 'NNP'), (\"'s\", 'POS'), ('GPT', 'NNP'), ('language', 'NN'), ('models', 'NNS'), ('into', 'IN'), ('its', 'PRP$'), ('products', 'NNS'), ('to', 'TO'), ('compete', 'VB'), ('with', 'IN'), ('Google', 'NNP'), (',', ','), ('and', 'CC'), (',', ','), ('the', 'DT'), ('company', 'NN'), ('now', 'RB'), ('claims', 'VBZ'), (',', ','), ('its', 'PRP$'), ('AI', 'NNP'), ('is', 'VBZ'), ('an', 'DT'), ('early', 'JJ'), ('form', 'NN'), ('of', 'IN'), ('artificial', 'JJ'), ('general', 'JJ'), ('intelligence', 'NN'), ('(', '('), ('AGI', 'NNP'), (')', ')'), ('.', '.'), ('On', 'IN'), ('Wednesday', 'NNP'), (',', ','), ('Microsoft', 'NNP'), ('researchers', 'NNS'), ('released', 'VBD'), ('a', 'DT'), ('paper', 'NN'), ('on', 'IN'), ('the', 'DT'), ('arXiv', 'JJ'), ('preprint', 'NN'), ('server', 'NN'), ('titled', 'VBN'), ('“', 'JJ'), ('Sparks', 'NNP'), ('of', 'IN'), ('Artificial', 'NNP'), ('General', 'NNP'), ('Intelligence', 'NNP'), (':', ':'), ('Early', 'JJ'), ('experiments', 'NNS'), ('with', 'IN'), ('GPT-4.', 'NNP'), ('”', 'NNP'), ('They', 'PRP'), ('declared', 'VBD'), ('that', 'IN'), ('GPT-4', 'NNP'), ('showed', 'VBD'), ('early', 'JJ'), ('signs', 'NNS'), ('of', 'IN'), ('AGI', 'NNP'), (',', ','), ('meaning', 'VBG'), ('that', 'IN'), ('it', 'PRP'), ('has', 'VBZ'), ('capabilities', 'NNS'), ('that', 'WDT'), ('are', 'VBP'), ('at', 'IN'), ('or', 'CC'), ('above', 'IN'), ('human', 'JJ'), ('level', 'NN'), ('.', '.'), ('This', 'DT'), ('eyebrow-raising', 'JJ'), ('conclusion', 'NN'), ('largely', 'RB'), ('contrasts', 'VBZ'), ('what', 'WP'), ('OpenAI', 'NNP'), ('CEO', 'NNP'), ('Sam', 'NNP'), ('Altman', 'NNP'), ('has', 'VBZ'), ('been', 'VBN'), ('saying', 'VBG'), ('regarding', 'VBG'), ('GPT-4', 'NNP'), ('.', '.'), ('For', 'IN'), ('example', 'NN'), (',', ','), ('he', 'PRP'), ('said', 'VBD'), ('the', 'DT'), ('model', 'NN'), ('was', 'VBD'), ('``', '``'), ('still', 'RB'), ('flawed', 'VBN'), (',', ','), ('still', 'RB'), ('limited', 'VBN'), ('.', '.'), (\"''\", \"''\"), ('In', 'IN'), ('fact', 'NN'), (',', ','), ('if', 'IN'), ('you', 'PRP'), ('read', 'VBP'), ('the', 'DT'), ('paper', 'NN'), ('itself', 'PRP'), (',', ','), ('the', 'DT'), ('researchers', 'NNS'), ('appear', 'VBP'), ('to', 'TO'), ('dial', 'VB'), ('back', 'RP'), ('their', 'PRP$'), ('own', 'JJ'), ('splashy', 'JJ'), ('claim', 'NN'), (':', ':'), ('the', 'DT'), ('bulk', 'NN'), ('of', 'IN'), ('the', 'DT'), ('paper', 'NN'), ('is', 'VBZ'), ('dedicated', 'VBN'), ('to', 'TO'), ('listing', 'VBG'), ('the', 'DT'), ('number', 'NN'), ('of', 'IN'), ('limitations', 'NNS'), ('and', 'CC'), ('biases', 'VBZ'), ('the', 'DT'), ('large', 'JJ'), ('language', 'NN'), ('model', 'NN'), ('contains', 'VBZ'), ('.', '.'), ('This', 'DT'), ('begs', 'VBZ'), ('the', 'DT'), ('question', 'NN'), ('of', 'IN'), ('how', 'WRB'), ('close', 'JJ'), ('to', 'TO'), ('AGI', 'NNP'), ('GPT-4', 'NNP'), ('really', 'RB'), ('is', 'VBZ'), (',', ','), ('and', 'CC'), ('how', 'WRB'), ('AGI', 'NNP'), ('is', 'VBZ'), ('instead', 'RB'), ('being', 'VBG'), ('used', 'VBN'), ('as', 'IN'), ('clickbait', 'NN'), ('.', '.'), ('“', 'IN'), ('We', 'PRP'), ('demonstrate', 'VBP'), ('that', 'IN'), (',', ','), ('beyond', 'IN'), ('its', 'PRP$'), ('mastery', 'NN'), ('of', 'IN'), ('language', 'NN'), (',', ','), ('GPT-4', 'NNP'), ('can', 'MD'), ('solve', 'VB'), ('novel', 'JJ'), ('and', 'CC'), ('difficult', 'JJ'), ('tasks', 'NNS'), ('that', 'IN'), ('span', 'VBP'), ('mathematics', 'NNS'), (',', ','), ('coding', 'VBG'), (',', ','), ('vision', 'NN'), (',', ','), ('medicine', 'NN'), (',', ','), ('law', 'NN'), (',', ','), ('psychology', 'NN'), ('and', 'CC'), ('more', 'JJR'), (',', ','), ('without', 'IN'), ('needing', 'VBG'), ('any', 'DT'), ('special', 'JJ'), ('prompting', 'NN'), (',', ','), ('”', 'VBZ'), ('the', 'DT'), ('researchers', 'NNS'), ('write', 'VBP'), ('in', 'IN'), ('the', 'DT'), ('paper', 'NN'), ('’', 'NNP'), ('s', 'NN'), ('abstract', 'NN'), ('.', '.'), ('“', 'NN'), ('Moreover', 'RB'), (',', ','), ('in', 'IN'), ('all', 'DT'), ('of', 'IN'), ('these', 'DT'), ('tasks', 'NNS'), (',', ','), ('GPT-4', 'NNP'), ('’', 'NNP'), ('s', 'JJ'), ('performance', 'NN'), ('is', 'VBZ'), ('strikingly', 'RB'), ('close', 'JJ'), ('to', 'TO'), ('human-level', 'JJ'), ('performance', 'NN'), (',', ','), ('and', 'CC'), ('often', 'RB'), ('vastly', 'RB'), ('surpasses', 'VBZ'), ('prior', 'JJ'), ('models', 'NNS'), ('such', 'JJ'), ('as', 'IN'), ('ChatGPT', 'NNP'), ('.', '.'), ('Given', 'VBN'), ('the', 'DT'), ('breadth', 'NN'), ('and', 'CC'), ('depth', 'NN'), ('of', 'IN'), ('GPT-4', 'NNP'), ('’', 'NNP'), ('s', 'NN'), ('capabilities', 'NNS'), (',', ','), ('we', 'PRP'), ('believe', 'VBP'), ('that', 'IN'), ('it', 'PRP'), ('could', 'MD'), ('reasonably', 'RB'), ('be', 'VB'), ('viewed', 'VBN'), ('as', 'IN'), ('an', 'DT'), ('early', 'JJ'), ('(', '('), ('yet', 'RB'), ('still', 'RB'), ('incomplete', 'JJ'), (')', ')'), ('version', 'NN'), ('of', 'IN'), ('an', 'DT'), ('artificial', 'JJ'), ('general', 'JJ'), ('intelligence', 'NN'), ('(', '('), ('AGI', 'NNP'), (')', ')'), ('system.', 'VBD'), ('”', 'NNP'), ('Indeed', 'RB'), (',', ','), ('the', 'DT'), ('researchers', 'NNS'), ('show', 'VBP'), ('examples', 'NNS'), ('of', 'IN'), ('GPT-4', 'NNP'), ('’', 'NNP'), ('s', 'NN'), ('capabilities', 'NNS'), ('in', 'IN'), ('the', 'DT'), ('paper', 'NN'), (':', ':'), ('it', 'PRP'), ('is', 'VBZ'), ('able', 'JJ'), ('to', 'TO'), ('write', 'VB'), ('a', 'DT'), ('proof', 'NN'), ('about', 'IN'), ('how', 'WRB'), ('there', 'EX'), ('are', 'VBP'), ('infinitely', 'RB'), ('many', 'JJ'), ('primes', 'NNS'), (',', ','), ('with', 'IN'), ('rhymes', 'NNS'), ('on', 'IN'), ('every', 'DT'), ('line', 'NN'), (',', ','), ('and', 'CC'), ('draw', 'VB'), ('a', 'DT'), ('unicorn', 'JJ'), ('in', 'IN'), ('TiKZ', 'NNP'), (',', ','), ('a', 'DT'), ('drawing', 'VBG'), ('program', 'NN'), ('.', '.'), ('This', 'DT'), ('is', 'VBZ'), ('all', 'DT'), ('quickly', 'RB'), ('followed', 'VBN'), ('by', 'IN'), ('some', 'DT'), ('serious', 'JJ'), ('caveats', 'NNS'), ('.', '.'), ('While', 'IN'), ('in', 'IN'), ('the', 'DT'), ('abstract', 'NN'), ('of', 'IN'), ('the', 'DT'), ('paper', 'NN'), ('the', 'DT'), ('researchers', 'NNS'), ('write', 'VBP'), ('that', 'IN'), ('“', 'JJ'), ('GPT-4', 'NNP'), ('’', 'NNP'), ('s', 'JJ'), ('performance', 'NN'), ('is', 'VBZ'), ('strikingly', 'RB'), ('close', 'JJ'), ('to', 'TO'), ('human-level', 'JJ'), ('performance', 'NN'), (',', ','), ('”', 'VBP'), ('their', 'PRP$'), ('introduction', 'NN'), ('immediately', 'RB'), ('contradicts', 'VBZ'), ('that', 'IN'), ('initial', 'JJ'), ('attention-grabbing', 'JJ'), ('statement', 'NN'), ('.', '.'), ('They', 'PRP'), ('write', 'VBP'), (',', ','), ('“', 'JJ'), ('Our', 'PRP$'), ('claim', 'NN'), ('that', 'IN'), ('GPT-4', 'NNP'), ('represents', 'VBZ'), ('progress', 'NN'), ('towards', 'NNS'), ('AGI', 'NNP'), ('does', 'VBZ'), ('not', 'RB'), ('mean', 'VB'), ('that', 'IN'), ('it', 'PRP'), ('is', 'VBZ'), ('perfect', 'JJ'), ('at', 'IN'), ('what', 'WP'), ('it', 'PRP'), ('does', 'VBZ'), (',', ','), ('or', 'CC'), ('that', 'IN'), ('it', 'PRP'), ('comes', 'VBZ'), ('close', 'RB'), ('to', 'TO'), ('being', 'VBG'), ('able', 'JJ'), ('to', 'TO'), ('do', 'VB'), ('anything', 'NN'), ('that', 'IN'), ('a', 'DT'), ('human', 'JJ'), ('can', 'MD'), ('do', 'VB'), ('(', '('), ('which', 'WDT'), ('is', 'VBZ'), ('one', 'CD'), ('of', 'IN'), ('the', 'DT'), ('usual', 'JJ'), ('definition', 'NN'), ('[', 'NNP'), ('sic', 'JJ'), (']', 'NN'), ('of', 'IN'), ('AGI', 'NNP'), (';', ':'), ('see', 'VB'), ('the', 'DT'), ('conclusion', 'NN'), ('section', 'NN'), ('for', 'IN'), ('more', 'JJR'), ('on', 'IN'), ('this', 'DT'), (')', ')'), (',', ','), ('or', 'CC'), ('that', 'IN'), ('it', 'PRP'), ('has', 'VBZ'), ('inner', 'VBN'), ('motivation', 'NN'), ('and', 'CC'), ('goals', 'NNS'), ('(', '('), ('another', 'DT'), ('key', 'NN'), ('aspect', 'NN'), ('in', 'IN'), ('some', 'DT'), ('definitions', 'NNS'), ('of', 'IN'), ('AGI', 'NNP'), (')', ')'), ('.', '.'), ('”', 'VB'), ('The', 'DT'), ('researchers', 'NNS'), ('said', 'VBD'), ('that', 'IN'), ('they', 'PRP'), ('used', 'VBD'), ('a', 'DT'), ('1994', 'CD'), ('definition', 'NN'), ('of', 'IN'), ('AGI', 'NNP'), ('by', 'IN'), ('a', 'DT'), ('group', 'NN'), ('of', 'IN'), ('psychologists', 'NNS'), ('as', 'IN'), ('the', 'DT'), ('framework', 'NN'), ('for', 'IN'), ('their', 'PRP$'), ('research', 'NN'), ('.', '.'), ('They', 'PRP'), ('wrote', 'VBD'), (',', ','), ('“', 'VBD'), ('The', 'DT'), ('consensus', 'NN'), ('group', 'NN'), ('defined', 'VBD'), ('intelligence', 'NN'), ('as', 'IN'), ('a', 'DT'), ('very', 'RB'), ('general', 'JJ'), ('mental', 'NN'), ('capability', 'NN'), ('that', 'IN'), (',', ','), ('among', 'IN'), ('other', 'JJ'), ('things', 'NNS'), (',', ','), ('involves', 'VBZ'), ('the', 'DT'), ('ability', 'NN'), ('to', 'TO'), ('reason', 'NN'), (',', ','), ('plan', 'NN'), (',', ','), ('solve', 'VB'), ('problems', 'NNS'), (',', ','), ('think', 'VBP'), ('abstractly', 'RB'), (',', ','), ('comprehend', 'VBP'), ('complex', 'JJ'), ('ideas', 'NNS'), (',', ','), ('learn', 'JJ'), ('quickly', 'RB'), ('and', 'CC'), ('learn', 'VB'), ('from', 'IN'), ('experience', 'NN'), ('.', '.'), ('This', 'DT'), ('definition', 'NN'), ('implies', 'VBZ'), ('that', 'IN'), ('intelligence', 'NN'), ('is', 'VBZ'), ('not', 'RB'), ('limited', 'VBN'), ('to', 'TO'), ('a', 'DT'), ('specific', 'JJ'), ('domain', 'NN'), ('or', 'CC'), ('task', 'NN'), (',', ','), ('but', 'CC'), ('rather', 'RB'), ('encompasses', 'VBZ'), ('a', 'DT'), ('broad', 'JJ'), ('range', 'NN'), ('of', 'IN'), ('cognitive', 'JJ'), ('skills', 'NNS'), ('and', 'CC'), ('abilities.', 'JJ'), ('”', 'NNP'), ('“', 'NNP'), ('OpenAI', 'NNP'), ('’', 'NNP'), ('s', 'VBD'), ('powerful', 'JJ'), ('GPT-4', 'NNP'), ('model', 'NN'), ('challenges', 'VBZ'), ('many', 'JJ'), ('widely', 'RB'), ('held', 'VBN'), ('assumptions', 'NNS'), ('about', 'IN'), ('the', 'DT'), ('nature', 'NN'), ('of', 'IN'), ('machine', 'NN'), ('intelligence', 'NN'), ('.', '.'), ('Through', 'IN'), ('critical', 'JJ'), ('evaluation', 'NN'), ('of', 'IN'), ('the', 'DT'), ('system', 'NN'), ('’', 'NNP'), ('s', 'NN'), ('capabilities', 'NNS'), ('and', 'CC'), ('limitations', 'NNS'), (',', ','), ('which', 'WDT'), ('you', 'PRP'), ('can', 'MD'), ('read', 'VB'), ('about', 'IN'), ('in', 'IN'), ('‘', 'JJ'), ('Sparks', 'NNP'), ('of', 'IN'), ('Artificial', 'NNP'), ('General', 'NNP'), ('Intelligence', 'NNP'), (':', ':'), ('Early', 'JJ'), ('experiments', 'NNS'), ('with', 'IN'), ('GPT-4', 'NNP'), (',', ','), ('’', 'NNP'), ('Microsoft', 'NNP'), ('researchers', 'NNS'), ('observed', 'VBD'), ('fundamental', 'JJ'), ('leaps', 'NNS'), ('in', 'IN'), ('GPT-4', 'NNP'), ('’', 'NNP'), ('s', 'NN'), ('abilities', 'NNS'), ('to', 'TO'), ('reason', 'NN'), (',', ','), ('plan', 'NN'), (',', ','), ('solve', 'VB'), ('problems', 'NNS'), (',', ','), ('and', 'CC'), ('synthesize', 'VB'), ('complex', 'JJ'), ('ideas', 'NNS'), ('that', 'WDT'), ('signal', 'VBP'), ('a', 'DT'), ('paradigm', 'NN'), ('shift', 'NN'), ('in', 'IN'), ('the', 'DT'), ('field', 'NN'), ('of', 'IN'), ('computer', 'NN'), ('science', 'NN'), (',', ','), ('”', 'VB'), ('a', 'DT'), ('Microsoft', 'NNP'), ('spokesperson', 'NN'), ('said', 'VBD'), ('.', '.'), ('“', 'NN'), ('We', 'PRP'), ('recognize', 'VBP'), ('the', 'DT'), ('current', 'JJ'), ('limitations', 'NNS'), ('of', 'IN'), ('GPT-4', 'NNP'), ('and', 'CC'), ('that', 'IN'), ('there', 'EX'), ('is', 'VBZ'), ('still', 'RB'), ('work', 'VB'), ('to', 'TO'), ('be', 'VB'), ('done', 'VBN'), ('.', '.'), ('We', 'PRP'), ('will', 'MD'), ('continue', 'VB'), ('to', 'TO'), ('engage', 'VB'), ('the', 'DT'), ('broader', 'JJR'), ('scientific', 'JJ'), ('community', 'NN'), ('in', 'IN'), ('exploring', 'VBG'), ('future', 'JJ'), ('research', 'NN'), ('directions', 'NNS'), (',', ','), ('including', 'VBG'), ('those', 'DT'), ('required', 'VBN'), ('to', 'TO'), ('address', 'VB'), ('the', 'DT'), ('societal', 'NN'), ('and', 'CC'), ('ethical', 'JJ'), ('implications', 'NNS'), ('of', 'IN'), ('these', 'DT'), ('increasingly', 'RB'), ('intelligent', 'JJ'), ('systems.', 'NN'), ('”', 'NNP'), ('OpenAI', 'NNP'), ('CEO', 'NNP'), ('Sam', 'NNP'), ('Altman', 'NNP'), ('emphasized', 'VBD'), ('the', 'DT'), ('limitations', 'NNS'), ('of', 'IN'), ('GPT-4', 'NNP'), ('when', 'WRB'), ('it', 'PRP'), ('was', 'VBD'), ('released', 'VBN'), (',', ','), ('saying', 'VBG'), ('“', 'NN'), ('it', 'PRP'), ('is', 'VBZ'), ('still', 'RB'), ('flawed', 'VBN'), (',', ','), ('still', 'RB'), ('limited', 'VBN'), (',', ','), ('and', 'CC'), ('it', 'PRP'), ('still', 'RB'), ('seems', 'VBZ'), ('more', 'RBR'), ('impressive', 'JJ'), ('on', 'IN'), ('first', 'JJ'), ('use', 'NN'), ('than', 'IN'), ('it', 'PRP'), ('does', 'VBZ'), ('when', 'WRB'), ('you', 'PRP'), ('spend', 'VBP'), ('more', 'JJR'), ('time', 'NN'), ('with', 'IN'), ('it.', 'JJ'), ('”', 'NN'), ('In', 'IN'), ('a', 'DT'), ('Thursday', 'NNP'), ('interview', 'NN'), ('with', 'IN'), ('Intelligencer', 'NNP'), ('’', 'NNP'), ('s', 'VBD'), ('Kara', 'NNP'), ('Swisher', 'NNP'), (',', ','), ('Altman', 'NNP'), ('shared', 'VBD'), ('the', 'DT'), ('same', 'JJ'), ('disclaimers', 'NNS'), (':', ':'), ('“', 'NN'), ('There', 'EX'), ('’', 'NNP'), ('s', 'VBD'), ('plenty', 'NN'), ('of', 'IN'), ('things', 'NNS'), ('it', 'PRP'), ('’', 'VBZ'), ('s', 'NN'), ('still', 'RB'), ('bad', 'JJ'), ('at.', 'JJ'), ('”', 'NN'), ('In', 'IN'), ('the', 'DT'), ('interview', 'NN'), (',', ','), ('Altman', 'NNP'), ('agrees', 'VBZ'), ('that', 'IN'), ('the', 'DT'), ('bot', 'NN'), ('will', 'MD'), ('sometimes', 'RB'), ('make', 'VB'), ('things', 'NNS'), ('up', 'RB'), ('and', 'CC'), ('present', 'JJ'), ('users', 'NNS'), ('with', 'IN'), ('misinformation', 'NN'), ('.', '.'), ('He', 'PRP'), ('said', 'VBD'), ('that', 'IN'), ('there', 'EX'), ('still', 'RB'), ('needs', 'VBZ'), ('a', 'DT'), ('lot', 'NN'), ('more', 'JJR'), ('human', 'JJ'), ('feedback', 'NN'), ('to', 'TO'), ('be', 'VB'), ('more', 'RBR'), ('reliable', 'JJ'), ('.', '.'), ('Altman', 'NNP'), ('and', 'CC'), ('OpenAI', 'NNP'), ('have', 'VBP'), ('always', 'RB'), ('looked', 'VBN'), ('toward', 'IN'), ('a', 'DT'), ('future', 'NN'), ('where', 'WRB'), ('AGI', 'NNP'), ('exists', 'VBZ'), (',', ','), ('and', 'CC'), ('have', 'VBP'), ('recently', 'RB'), ('been', 'VBN'), ('engaged', 'VBN'), ('in', 'IN'), ('building', 'VBG'), ('hype', 'NN'), ('around', 'IN'), ('the', 'DT'), ('firm', 'NN'), (\"'s\", 'POS'), ('ability', 'NN'), ('to', 'TO'), ('bring', 'VB'), ('it', 'PRP'), ('about', 'RB'), ('.', '.'), ('But', 'CC'), ('Altman', 'NNP'), ('has', 'VBZ'), ('also', 'RB'), ('been', 'VBN'), ('clear', 'JJ'), ('that', 'IN'), ('GPT-4', 'NNP'), ('is', 'VBZ'), ('not', 'RB'), ('AGI', 'NNP'), ('.', '.'), ('“', 'VB'), ('The', 'DT'), ('GPT-4', 'NNP'), ('rumor', 'NN'), ('mill', 'NN'), ('is', 'VBZ'), ('a', 'DT'), ('ridiculous', 'JJ'), ('thing', 'NN'), ('.', '.'), ('I', 'PRP'), ('don', 'VBP'), ('’', 'JJ'), ('t', 'NN'), ('know', 'VBP'), ('where', 'WRB'), ('it', 'PRP'), ('all', 'DT'), ('comes', 'VBZ'), ('from', 'IN'), (',', ','), ('”', 'NNP'), ('Altman', 'NNP'), ('said', 'VBD'), ('just', 'RB'), ('before', 'IN'), ('GPT-4', 'NNP'), (\"'s\", 'POS'), ('release', 'NN'), ('.', '.'), ('“', 'JJ'), ('People', 'NNS'), ('are', 'VBP'), ('begging', 'VBG'), ('to', 'TO'), ('be', 'VB'), ('disappointed', 'VBN'), ('and', 'CC'), ('they', 'PRP'), ('will', 'MD'), ('be', 'VB'), ('.', '.'), ('The', 'DT'), ('hype', 'NN'), ('is', 'VBZ'), ('just', 'RB'), ('like', 'JJ'), ('...', ':'), ('We', 'PRP'), ('don', 'VBP'), ('’', 'JJ'), ('t', 'NN'), ('have', 'VBP'), ('an', 'DT'), ('actual', 'JJ'), ('AGI', 'NNP'), ('and', 'CC'), ('that', 'IN'), ('’', 'NNP'), ('s', 'VBD'), ('sort', 'NN'), ('of', 'IN'), ('what', 'WP'), ('’', 'NNP'), ('s', 'VBD'), ('expected', 'VBN'), ('of', 'IN'), ('us.', 'JJ'), ('”', 'NN'), (\"''\", \"''\"), ('Microsoft', 'NNP'), ('is', 'VBZ'), ('not', 'RB'), ('focused', 'VBN'), ('on', 'IN'), ('trying', 'VBG'), ('to', 'TO'), ('achieve', 'VB'), ('AGI', 'NNP'), ('.', '.'), ('Our', 'PRP$'), ('development', 'NN'), ('of', 'IN'), ('AI', 'NNP'), ('is', 'VBZ'), ('centered', 'VBN'), ('on', 'IN'), ('amplifying', 'NN'), (',', ','), ('augmenting', 'VBG'), (',', ','), ('and', 'CC'), ('assisting', 'VBG'), ('human', 'JJ'), ('productivity', 'NN'), ('and', 'CC'), ('capability', 'NN'), ('.', '.'), ('We', 'PRP'), ('are', 'VBP'), ('creating', 'VBG'), ('platforms', 'NNS'), ('and', 'CC'), ('tools', 'NNS'), ('that', 'IN'), (',', ','), ('rather', 'RB'), ('than', 'IN'), ('acting', 'VBG'), ('as', 'IN'), ('a', 'DT'), ('substitute', 'NN'), ('for', 'IN'), ('human', 'JJ'), ('effort', 'NN'), (',', ','), ('can', 'MD'), ('help', 'VB'), ('humans', 'NNS'), ('with', 'IN'), ('cognitive', 'JJ'), ('work', 'NN'), (',', ','), ('”', 'VB'), ('a', 'DT'), ('Microsoft', 'NNP'), ('spokesperson', 'NN'), ('clarified', 'VBD'), ('in', 'IN'), ('a', 'DT'), ('statement', 'NN'), ('to', 'TO'), ('Motherboard', 'NNP'), ('.', '.'), ('The', 'DT'), ('Microsoft', 'NNP'), ('researchers', 'NNS'), ('write', 'VBP'), ('that', 'IN'), ('the', 'DT'), ('model', 'NN'), ('has', 'VBZ'), ('trouble', 'NN'), ('with', 'IN'), ('confidence', 'NN'), ('calibration', 'NN'), (',', ','), ('long-term', 'JJ'), ('memory', 'NN'), (',', ','), ('personalization', 'NN'), (',', ','), ('planning', 'NN'), ('and', 'CC'), ('conceptual', 'JJ'), ('leaps', 'NNS'), (',', ','), ('transparency', 'NN'), (',', ','), ('interpretability', 'NN'), ('and', 'CC'), ('consistency', 'NN'), (',', ','), ('cognitive', 'JJ'), ('fallacies', 'NNS'), ('and', 'CC'), ('irrationality', 'NN'), (',', ','), ('and', 'CC'), ('challenges', 'NNS'), ('with', 'IN'), ('sensitivity', 'NN'), ('to', 'TO'), ('inputs', 'VB'), ('.', '.'), ('What', 'WP'), ('all', 'PDT'), ('this', 'DT'), ('means', 'VBZ'), ('is', 'VBZ'), ('that', 'IN'), ('the', 'DT'), ('model', 'NN'), ('has', 'VBZ'), ('trouble', 'NN'), ('knowing', 'VBG'), ('when', 'WRB'), ('it', 'PRP'), ('is', 'VBZ'), ('confident', 'JJ'), ('or', 'CC'), ('when', 'WRB'), ('it', 'PRP'), ('is', 'VBZ'), ('just', 'RB'), ('guessing', 'NN'), (',', ','), ('it', 'PRP'), ('makes', 'VBZ'), ('up', 'RP'), ('facts', 'NNS'), ('that', 'WDT'), ('are', 'VBP'), ('not', 'RB'), ('in', 'IN'), ('its', 'PRP$'), ('training', 'NN'), ('data', 'NNS'), (',', ','), ('the', 'DT'), ('model', 'NN'), ('’', 'NNP'), ('s', 'NN'), ('context', 'NN'), ('is', 'VBZ'), ('limited', 'JJ'), ('and', 'CC'), ('there', 'EX'), ('is', 'VBZ'), ('no', 'DT'), ('obvious', 'JJ'), ('way', 'NN'), ('to', 'TO'), ('teach', 'VB'), ('the', 'DT'), ('model', 'NN'), ('new', 'JJ'), ('facts', 'NNS'), (',', ','), ('the', 'DT'), ('model', 'NN'), ('can', 'MD'), ('’', 'VB'), ('t', 'JJ'), ('personalize', 'VB'), ('its', 'PRP$'), ('responses', 'NNS'), ('to', 'TO'), ('a', 'DT'), ('certain', 'JJ'), ('user', 'NN'), (',', ','), ('the', 'DT'), ('model', 'NN'), ('can', 'MD'), ('’', 'VB'), ('t', 'JJ'), ('make', 'VB'), ('conceptual', 'JJ'), ('leaps', 'NNS'), (',', ','), ('the', 'DT'), ('model', 'NN'), ('has', 'VBZ'), ('no', 'DT'), ('way', 'NN'), ('to', 'TO'), ('verify', 'VB'), ('if', 'IN'), ('content', 'NN'), ('is', 'VBZ'), ('consistent', 'JJ'), ('with', 'IN'), ('its', 'PRP$'), ('training', 'NN'), ('data', 'NNS'), (',', ','), ('the', 'DT'), ('model', 'NN'), ('inherits', 'VBZ'), ('biases', 'NNS'), (',', ','), ('prejudices', 'NNS'), (',', ','), ('and', 'CC'), ('errors', 'NNS'), ('in', 'IN'), ('the', 'DT'), ('training', 'NN'), ('data', 'NNS'), (',', ','), ('and', 'CC'), ('the', 'DT'), ('model', 'NN'), ('is', 'VBZ'), ('very', 'RB'), ('sensitive', 'JJ'), ('to', 'TO'), ('the', 'DT'), ('framing', 'NN'), ('and', 'CC'), ('wording', 'NN'), ('of', 'IN'), ('prompts', 'NNS'), ('.', '.'), ('GPT-4', 'NNP'), ('is', 'VBZ'), ('the', 'DT'), ('model', 'NN'), ('that', 'IN'), ('Bing', 'NNP'), ('’', 'NNP'), ('s', 'VBD'), ('chatbot', 'NN'), ('was', 'VBD'), ('built', 'VBN'), ('on', 'IN'), (',', ','), ('giving', 'VBG'), ('us', 'PRP'), ('an', 'DT'), ('example', 'NN'), ('of', 'IN'), ('how', 'WRB'), ('the', 'DT'), ('chatbot', 'NN'), ('’', 'NNP'), ('s', 'NN'), ('limitations', 'NNS'), ('are', 'VBP'), ('noticeably', 'RB'), ('exhibited', 'VBN'), ('in', 'IN'), ('a', 'DT'), ('real-life', 'JJ'), ('scenario', 'NN'), ('.', '.'), ('It', 'PRP'), ('made', 'VBD'), ('several', 'JJ'), ('mistakes', 'NNS'), ('during', 'IN'), ('Microsoft', 'NNP'), ('’', 'NNP'), ('s', 'VBZ'), ('public', 'JJ'), ('demo', 'NN'), ('of', 'IN'), ('the', 'DT'), ('project', 'NN'), (',', ','), ('making', 'VBG'), ('up', 'RP'), ('information', 'NN'), ('about', 'IN'), ('a', 'DT'), ('pet', 'JJ'), ('vacuum', 'NN'), ('and', 'CC'), ('Gap', 'NNP'), ('’', 'NNP'), ('s', 'VBP'), ('financial', 'JJ'), ('data', 'NNS'), ('.', '.'), ('When', 'WRB'), ('users', 'NNS'), ('chatted', 'VBD'), ('with', 'IN'), ('the', 'DT'), ('chatbot', 'NN'), (',', ','), ('it', 'PRP'), ('would', 'MD'), ('often', 'RB'), ('go', 'VB'), ('out', 'IN'), ('of', 'IN'), ('control', 'NN'), (',', ','), ('such', 'JJ'), ('as', 'IN'), ('saying', 'VBG'), ('“', 'NN'), ('I', 'PRP'), ('am', 'VBP'), ('.', '.'), ('I', 'PRP'), ('am', 'VBP'), ('not', 'RB'), ('.', '.'), ('I', 'PRP'), ('am', 'VBP'), ('.', '.'), ('I', 'PRP'), ('am', 'VBP'), ('not.', 'JJ'), ('”', 'NN'), ('over', 'IN'), ('fifty', 'JJ'), ('times', 'NNS'), ('in', 'IN'), ('a', 'DT'), ('row', 'NN'), ('as', 'IN'), ('a', 'DT'), ('response', 'NN'), ('to', 'TO'), ('someone', 'NN'), ('asking', 'VBG'), ('it', 'PRP'), (',', ','), ('“', 'VBZ'), ('Do', 'VBP'), ('you', 'PRP'), ('think', 'VB'), ('that', 'IN'), ('you', 'PRP'), ('are', 'VBP'), ('sentient', 'JJ'), ('?', '.'), ('”', 'CC'), ('Though', 'IN'), ('the', 'DT'), ('current', 'JJ'), ('version', 'NN'), ('of', 'IN'), ('GPT-4', 'NNP'), ('has', 'VBZ'), ('been', 'VBN'), ('fine-tuned', 'VBN'), ('on', 'IN'), ('user', 'NN'), ('interaction', 'NN'), ('since', 'IN'), ('Bing', 'NNP'), ('chatbot', 'NN'), ('’', 'NNP'), ('s', 'VBZ'), ('initial', 'JJ'), ('release', 'NN'), (',', ','), ('researchers', 'NNS'), ('found', 'VBD'), ('that', 'IN'), ('GPT-4', 'NNP'), ('spreads', 'VBZ'), ('more', 'JJR'), ('misinformation', 'NN'), ('than', 'IN'), ('its', 'PRP$'), ('predecessor', 'NN'), ('GPT-3.5', 'NNP'), ('.', '.'), ('Notably', 'RB'), (',', ','), ('the', 'DT'), ('researchers', 'NNS'), ('“', 'VBP'), ('do', 'VBP'), ('not', 'RB'), ('have', 'VB'), ('access', 'NN'), ('to', 'TO'), ('the', 'DT'), ('full', 'JJ'), ('details', 'NNS'), ('of', 'IN'), ('its', 'PRP$'), ('vast', 'JJ'), ('training', 'NN'), ('data', 'NNS'), (',', ','), ('”', 'NNP'), ('revealing', 'VBG'), ('that', 'IN'), ('their', 'PRP$'), ('conclusion', 'NN'), ('is', 'VBZ'), ('only', 'RB'), ('based', 'VBN'), ('on', 'IN'), ('testing', 'VBG'), ('the', 'DT'), ('model', 'NN'), ('on', 'IN'), ('standard', 'JJ'), ('benchmarks', 'NNS'), (',', ','), ('nonspecific', 'JJ'), ('to', 'TO'), ('GPT-4', 'NNP'), ('.', '.'), ('“', 'VB'), ('The', 'DT'), ('standard', 'JJ'), ('approach', 'NN'), ('in', 'IN'), ('machine', 'NN'), ('learning', 'NN'), ('is', 'VBZ'), ('to', 'TO'), ('evaluate', 'VB'), ('the', 'DT'), ('system', 'NN'), ('on', 'IN'), ('a', 'DT'), ('set', 'NN'), ('of', 'IN'), ('standard', 'JJ'), ('benchmark', 'NN'), ('datasets', 'NNS'), (',', ','), ('ensuring', 'VBG'), ('that', 'IN'), ('they', 'PRP'), ('are', 'VBP'), ('independent', 'JJ'), ('of', 'IN'), ('the', 'DT'), ('training', 'NN'), ('data', 'NNS'), ('and', 'CC'), ('that', 'IN'), ('they', 'PRP'), ('cover', 'VBP'), ('a', 'DT'), ('range', 'NN'), ('of', 'IN'), ('tasks', 'NNS'), ('and', 'CC'), ('domains', 'NNS'), (',', ','), ('”', 'VBP'), ('the', 'DT'), ('researchers', 'NNS'), ('wrote', 'VBD'), ('.', '.'), ('“', 'NN'), ('We', 'PRP'), ('have', 'VBP'), ('to', 'TO'), ('assume', 'VB'), ('that', 'IN'), ('it', 'PRP'), ('has', 'VBZ'), ('potentially', 'RB'), ('seen', 'VBN'), ('every', 'DT'), ('existing', 'VBG'), ('benchmark', 'NN'), (',', ','), ('or', 'CC'), ('at', 'IN'), ('least', 'JJS'), ('some', 'DT'), ('similar', 'JJ'), ('data.', 'NN'), ('”', 'VBD'), ('The', 'DT'), ('secrecy', 'NN'), ('that', 'WDT'), ('OpenAI', 'NNP'), ('has', 'VBZ'), ('surrounding', 'VBG'), ('the', 'DT'), ('training', 'NN'), ('datasets', 'NNS'), ('and', 'CC'), ('code', 'NN'), ('surrounding', 'VBG'), ('its', 'PRP$'), ('AI', 'NNP'), ('models', 'NNS'), ('is', 'VBZ'), ('something', 'NN'), ('that', 'IN'), ('many', 'JJ'), ('AI', 'NNP'), ('researchers', 'NNS'), ('have', 'VBP'), ('criticized', 'VBN'), (',', ','), ('as', 'IN'), ('they', 'PRP'), ('say', 'VBP'), (',', ','), ('this', 'DT'), ('makes', 'VBZ'), ('it', 'PRP'), ('impossible', 'JJ'), ('to', 'TO'), ('evaluate', 'VB'), ('the', 'DT'), ('model', 'NN'), ('’', 'NNP'), ('s', 'NN'), ('harms', 'NNS'), ('and', 'CC'), ('come', 'VB'), ('up', 'RP'), ('with', 'IN'), ('ways', 'NNS'), ('to', 'TO'), ('mitigate', 'VB'), ('the', 'DT'), ('model', 'NN'), ('’', 'NNP'), ('s', 'NN'), ('risks', 'NNS'), ('.', '.'), ('With', 'IN'), ('all', 'PDT'), ('this', 'DT'), ('being', 'VBG'), ('said', 'VBD'), (',', ','), ('it', 'PRP'), ('is', 'VBZ'), ('clear', 'JJ'), ('that', 'IN'), ('the', 'DT'), ('“', 'NNP'), ('sparks', 'VBZ'), ('”', 'IN'), ('the', 'DT'), ('researchers', 'NNS'), ('claim', 'VBP'), ('to', 'TO'), ('have', 'VB'), ('found', 'VBN'), ('are', 'VBP'), ('largely', 'RB'), ('overpowered', 'VBN'), ('by', 'IN'), ('the', 'DT'), ('number', 'NN'), ('of', 'IN'), ('limitations', 'NNS'), ('and', 'CC'), ('biases', 'NNS'), ('that', 'IN'), ('the', 'DT'), ('model', 'NN'), ('has', 'VBZ'), ('displayed', 'VBN'), ('since', 'IN'), ('its', 'PRP$'), ('release', 'NN'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "# POS (Part Of Speech) tagging\n",
    "\n",
    "tokens = nltk.word_tokenize(text)\n",
    "taggedTokens = nltk.pos_tag(tokens)\n",
    "print(taggedTokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Microsoft': 'NE', 'OpenAI': 'NE', 'GPT': 'NE', 'Google': 'NE', 'AGI': 'NE', 'arXiv': 'NE', 'Artificial': 'NE', 'ChatGPT': 'NE', 'TiKZ': 'NE', 'Intelligencer': 'NE', 'Kara Swisher': 'NE', 'Altman': 'NE', 'AI': 'NE', 'Motherboard': 'NE', 'Bing': 'NE', 'Gap': 'NE'}\n"
     ]
    }
   ],
   "source": [
    "# NER (Named Entity Recognition) with entity classification\n",
    "\n",
    "neChunked = nltk.ne_chunk(taggedTokens, binary=True)\n",
    "data = {}\n",
    "for entity in neChunked:\n",
    "    if isinstance(entity, nltk.tree.Tree):\n",
    "        text = \" \".join([word for word, tag in entity.leaves()])\n",
    "        ent = entity.label()\n",
    "        data[text] = ent\n",
    "\n",
    "print(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49\n",
      "['Microsoft', 'OpenAI', 'GPT language models', 'Google', 'AI', 'AGI', 'Wednesday', 'Microsoft researchers', 'Sparks of Artificial General Intelligence', 'GPT-4', 'OpenAI CEO Sam Altman', 'GPT-4', 'AGI GPT-4', 'AGI', 'GPT-4', 'GPT-4 ’', 'ChatGPT', 'AGI', 'TiKZ', 'GPT-4 ’', 'GPT-4 model', 'Sparks of Artificial General Intelligence', 'Microsoft spokesperson', 'Thursday interview with Intelligencer ’', 'Kara Swisher', 'Altman', 'Altman', 'Altman', 'OpenAI', 'AGI', 'Altman', 'GPT-4', 'AGI', 'GPT-4 rumor mill', 'GPT-4', 'People', 'AGI', 'Microsoft', 'AGI', 'Microsoft spokesperson', 'Motherboard', 'Microsoft researchers', 'GPT-4', 'Gap ’', 'GPT-4', 'GPT-4', 'OpenAI', 'AI models', 'AI researchers']\n"
     ]
    }
   ],
   "source": [
    "# Custom NER\n",
    "\n",
    "customData = []\n",
    "entity = []\n",
    "for taggedEntry in taggedTokens:\n",
    "    # NN = noun, singular (cat, tree) or NN = noun plural (desks) or IN = preposition/subordinating conjunction\n",
    "    if taggedEntry[1].startswith(\"NN\") or taggedEntry[1].startswith(\"NNS\") or (entity and taggedEntry[1].startswith(\"IN\")):\n",
    "        entity.append(taggedEntry)\n",
    "    else:\n",
    "        if (entity) and entity[-1][1].startswith(\"IN\"):  # pop last preposition\n",
    "            entity.pop()\n",
    "        if (entity and \" \".join(e[0] for e in entity)[0].isupper()):\n",
    "            customData.append(\" \".join(e[0] for e in entity))\n",
    "        entity = []\n",
    "\n",
    "print(len(customData))\n",
    "print(customData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NER + classification using existing language model (e.g. NER models from Hugging Face)\n",
    "\n",
    "from transformers import pipeline\n",
    "\n",
    "ner = pipeline(\"ner\", grouped_entities=True)\n",
    "ner(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/babakjan/Developer/ddw/hw/02/venv/lib/python3.11/site-packages/wikipedia/wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"html.parser\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file /Users/babakjan/Developer/ddw/hw/02/venv/lib/python3.11/site-packages/wikipedia/wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"html.parser\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'AGI': 'a feminist research',\n",
      " 'AGI GPT-4': 'Thing (page not found)',\n",
      " 'AI': 'Artificial intelligence',\n",
      " 'AI models': 'Thing (page not found)',\n",
      " 'AI researchers': 'Thing (page not found)',\n",
      " 'Altman': 'a surname',\n",
      " 'ChatGPT': 'an artificial intelligence chatbot',\n",
      " 'GPT language models': 'Thing (page not found)',\n",
      " 'GPT-4': 'large language model',\n",
      " 'GPT-4 model': 'Thing (page not found)',\n",
      " 'GPT-4 rumor mill': 'Thing (page not found)',\n",
      " 'GPT-4 ’': 'Thing (page not found)',\n",
      " 'Gap ’': 'Thing (page not found)',\n",
      " 'Google': 'an American multinational technology',\n",
      " 'Kara Swisher': 'an American journalist',\n",
      " 'Microsoft': 'an American multinational technology',\n",
      " 'Microsoft researchers': 'Thing (page not found)',\n",
      " 'Microsoft spokesperson': 'Thing (page not found)',\n",
      " 'Motherboard': 'A motherboard',\n",
      " 'OpenAI': 'artificial intelligence',\n",
      " 'OpenAI CEO Sam Altman': 'Thing (page not found)',\n",
      " 'People': 'A people',\n",
      " 'Sparks of Artificial General Intelligence': 'Thing (page not found)',\n",
      " 'Thursday interview with Intelligencer ’': 'Thing (page not found)',\n",
      " 'TiKZ': 'Thing (page not found)',\n",
      " 'Wednesday': 'the day'}\n"
     ]
    }
   ],
   "source": [
    "# custom entity classification\n",
    "\n",
    "import wikipedia\n",
    "import pprint\n",
    "\n",
    "# part of speech tags shortcuts https://www.guru99.com/pos-tagging-chunking-nltk.html\n",
    "# DT = delimiter\n",
    "# JJ = This NLTK POS Tag is an adjective (large)\n",
    "# VBN = verb past participle (reunified)\n",
    "# NN = noun, singular (cat, tree)\n",
    "# NNS = noun plural (desks)\n",
    "# IN = preposition/subordinating conjunction\n",
    "grammar = \"NP: {<DT>?<IN>?<JJ>?<VBN>*<NN|NNS>?<NN|NNS>}\"\n",
    "cp = nltk.RegexpParser(grammar)\n",
    "\n",
    "resultDict = {}\n",
    "\n",
    "for entity in customData:\n",
    "    summarySentence = None\n",
    "    try:\n",
    "        summarySentence = wikipedia.summary(\n",
    "            entity, auto_suggest=False, sentences=1)\n",
    "    except wikipedia.DisambiguationError as e:\n",
    "        summarySentence = wikipedia.summary(e.options[0], sentences=1)\n",
    "    except:\n",
    "        resultDict[entity] = \"Thing (page not found)\"\n",
    "        continue\n",
    "    tokenizedSentence = nltk.word_tokenize(summarySentence)\n",
    "    posTaggedSentence = nltk.pos_tag(tokenizedSentence)\n",
    "    parsedSentence = cp.parse(posTaggedSentence)\n",
    "    success = False\n",
    "    for chunk in parsedSentence:\n",
    "        if isinstance(chunk, nltk.tree.Tree):\n",
    "            text = \" \".join([word for word, tag in chunk.leaves()])\n",
    "            resultDict[entity] = text\n",
    "            success = True\n",
    "            break\n",
    "\n",
    "    if not success:\n",
    "        resultDict[entity] = \"Thing\"\n",
    "\n",
    "pprint.pprint(resultDict)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
